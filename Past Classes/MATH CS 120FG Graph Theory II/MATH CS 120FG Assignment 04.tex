\documentclass[12pt]{article}

% packages
\usepackage{kantlipsum}
\usepackage[margin=1in]{geometry}
\usepackage[labelfont=it]{caption}
\usepackage[table]{xcolor}
\usepackage{subcaption,framed,colortbl,multirow}
\usepackage{amsmath,amsthm,amssymb,wasysym,mathrsfs,mathtools}
\usepackage{tikz,graphicx,pgf,pgfplots}
\usetikzlibrary{arrows, angles, quotes, decorations.pathreplacing, math, patterns, calc}
\pgfplotsset{compat=1.16}

% Set Names
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}

% Misc Characters
\newcommand{\F}{\mathbb{F}}
\newcommand{\powerset}{\raisebox{.15\baselineskip}{\Large\ensuremath{\wp}}}
\newcommand{\eps}{\varepsilon}

% Paired Delimiters
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\ang}{\langle}{\rangle}

% Homework Sections
\setlength{\fboxsep}{4pt}
\newcommand{\generic}[2]{\section*{#1}\begin{center}\framebox{\begin{minipage}{\textwidth-10pt}#2\end{minipage}}\end{center}}
\newcommand{\ex}[2]{\generic{Exercise #1}{#2}}
\newcommand{\prob}[2]{\generic{Problem #1}{#2}}
\newcommand{\ques}[2]{\generic{Question #1}{#2}}

% Environments
\newenvironment{drawing}{\begin{center}\begin{tikzpicture}}{\end{tikzpicture}\end{center}}

% MATH CS 117 Intro to Real Analysis
\newcommand{\ds}{\displaystyle}
\newcommand{\seq}[1]{\left\{#1\right\}_{n=1}^\infty}
\newcommand{\isp}[1]{\quad\text{#1}\quad}
 
\begin{document}
 
\title{Assignment 4\\
    \large MATH CS 120FG Graph Theory II}
\author{Harry Coleman}
\date{May 8, 2020}
\maketitle

\ex{1}{
    Prove that if $v\in\Z_2^n$ and $v\ne0\cdots0$, then
    \[\sum_{w\in\Z_2^n}(-1)^{v\cdot w} = 0.\]
}

Let $v\in\Z_2^n$ such that $v\ne0\cdots0$, and suppose the $i$th digit of $v$ is a 1. Now for each $w\in\Z_2^n$, we define $\overline{w}$ in terms of each digit:
\[\overline{w}_j = \begin{cases}
    w_j &\text{if } j\ne i, \\
    0 &\text{if } j=i \text{ and } w_j=1, \\
    1 &\text{if } j=i \text{ and } w_j=0. \\
\end{cases}\]
In other words, $\overline{w}$ is the same as $w$ except for the $i$th digit flipped. This means that the elements of $\Z_2^n$ pair uniquely into $w$ and $\overline{w}$ pairs. And since $v_i=1$, this means that $v\cdot w$ and $v\cdot\overline{w}$ differ by exactly one, which implies that one is odd and the other even. Therefore $(-1)^{v\cdot w}+(-1)^{v\cdot\overline{w}} = 0$. And again, since the elements uniquely pair in this way,
\[\sum_{w\in\Z_2^n}(-1)^{v\cdot w} = 0.\]


\newpage
\ex{2}{
    Prove that the eigenvalues for $A(Q_n)$ have the form $\lambda_v = n - 2\omega(v)$, for $v \in\Z_2^n$, where $\omega(v)$ is the number of 1â€™s in $v$.
}

Let $\beta=\{\delta_v: v\in\Z_2^n\}$ and $\Gamma=\{e_1,\dots,e_n\}$, so
\[[\Phi_\Gamma]_\beta = A(Q_n),\]
and we have the eigenvalues $\{\lambda_v : v\in\Z_2^n\}$. In particular, for each $v\in\Z_2^n$, we have
\[\lambda_v = \sum_{w\in\Gamma}(-1)^{v\cdot w} = \sum_{i=1}^n(-1)^{v\cdot e_i}.\]
Notice that $v\cdot e_i = v_i$, so for each $i$ in the above sum, we subtract 1 for each 1-digit in $v$ and add 1 for each 0-digit in $v$. So if $v=0\cdots0$, then $\lambda_v=n$, and for each 1-digit in $v$, we replace adding 1 with subtracting 1 in the above sum. In other words, we start with $n$ and subtract 2 for each 1-digit in $v$. So indeed,
\[\lambda_v = n-2\omega(v).\]
Also note that $\lambda_v$ has multiplicity $\ds{n\choose \omega(v)}$ since there are as many elements of $\Z_2^n$ with the same number of 1-digits.


\newpage
\ex{3}{
    For this question, use the results from the videos. Suppose we start with $n$ coins, all with heads up. Choose a coin at random (each equally likely) and flip it. Do this a total of $\ell$ times.
    \begin{enumerate}
        \item What is the probability that at the end, all coins are again heads up?
        \item What is the probability that at the end, all coins are tails up?
    \end{enumerate}
}

We first notice that all the possible states of the $n$ coins correspond to the vertices of $Q_n$, and that coin states are adjacent in $Q_n$ when they differ in exactly one place which corresponds to flipping one of the coins. So a series of $\ell$ flips is a walk of length $\ell$ in $Q_n$. In particular, such a walk starting and ending at all the coins being heads would be a closed walk in $Q_n$ starting and ending at $0\cdots0$. Since the number of closed walks in $Q_n$ of length $\ell$ is given by
\[\sum_{v\in\Z_2^n}\lambda_v^\ell,\]
and from exercise 2, we know the form and multiplicity of the eigenvalues. So this is equal to
\[\sum_{k=0}^n(n-2k)^\ell{n \choose k}.\]
To get the number closed walks starting at $0\cdots0$, we divide this by the number of vertices, $2^n$, since the set of walks for each vertex is symmetric to all the others. And to get the probability of such a walk, we divide by the total number of walks, $n^\ell$, since at each of $\ell$ steps, we might flip any of $n$ coins. This gives us the probability that at the end, all coins are heads up to be
\[\frac{\ds\sum_{k=0}^n(n-2k)^\ell{n \choose k}}{2^nn^\ell}.\]

Similarly, ending up with all tails corresponds to a walk from $\textbf{0}=0\cdots0$ to $\textbf{1}=1\cdots1$ of length $\ell$. The number of such walks is given by
\[(A(Q_n)^\ell)_{\textbf{0}\textbf{1}} = (([\Phi_\Gamma]_\beta)^\ell)_{\textbf{0}\textbf{1}},\]
where $\beta=\{\delta_v : v\in\Z_2^n\}$. If we instead consider the basis $\gamma=\{\chi_v : v\in\Z_2^n\}$ for $V$, then we find
\begin{align*}
    [\Phi_\Gamma]_\gamma &=
        \begin{bmatrix}
        | & & | \\
        [\Phi_\Gamma(\chi_{0\dots0})]_\gamma & \cdots & [\Phi_\Gamma(\chi_{1\dots1})]_\gamma \\
        | & & |
    \end{bmatrix} \\
    &=
    \begin{bmatrix}
        | & & | \\
        [\lambda_{0\cdots0}\chi_{0\dots0}]_\gamma & \cdots & [\lambda_{1\cdots1}\chi_{1\dots1}]_\gamma \\
        | & & |
    \end{bmatrix} \\
    &=
    \begin{bmatrix}
        \lambda_{0\cdots0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & \lambda_{2\cdots2}
    \end{bmatrix}.
\end{align*}
Denoting $[\Phi_\Gamma]_\gamma$ by $D$, we have
\[ D_{ij} = \begin{cases}
    \lambda_i &\text{if } i=j, \\
    0 &\text{if } i\ne j,
\end{cases}\]
and
\[[\Phi_\Gamma]_\beta = Q_\gamma^\beta D Q_\beta^\gamma,\]
We will define $P=Q_\gamma^\beta$, so
\[P_{ij} = ([\chi_j]_\beta)_i = \chi_j(i) = (-1)^{i\cdot j},\]
Now $P$ is not orthogonal, but the columns are orthogonal and all entries are either $1$ or $-1$. So if we take $\ds\frac1{\sqrt{2^n}}P$, then the norm of each column becomes 1, giving us an orthogonal matrix. So
\begin{align*}
    \left(\ds\frac1{\sqrt{2^n}}P\right)^{-1} &= \left(\ds\frac1{\sqrt{2^n}}P\right)^T, \\
    \sqrt{2^n}P^{-1} &= \ds\frac1{\sqrt{2^n}}P^T, \\
    P^{-1} &= \ds\frac1{2^n}P^T.
\end{align*}
Thus $[\Phi_\Gamma]_\beta = PDP^{-1} = \left(\frac{P}{\sqrt{2^n}}\right)D\left(\frac{P}{\sqrt{2^n}}\right)^T$, where $\left(\frac{P}{\sqrt{2^n}}\right)$ is an orthogonal matrix. So now,
\begin{align*}
    (A(Q_n)^\ell)_{\textbf{0}\textbf{1}} 
        &= (([\Phi_\Gamma]_\beta)^\ell)_{\textbf{0}\textbf{1}} \\
        &= \left(\left(\frac{P}{\sqrt{2^n}}\right)D^\ell \left(\frac{P}{\sqrt{2^n}}\right)^T\right)_{\textbf{0}\textbf{1}} \\
        &= \frac1{2^n}(PD^\ell P^T)_{\textbf{0}\textbf{1}} \\
        &= \frac1{2^n}\sum_{i\in\Z_2^n}(PD^\ell)_{\textbf{0}i}P^T_{i\textbf{1}} \\
        &= \frac1{2^n}\sum_{i\in\Z_2^n}\sum_{j\in\Z_2^n}P_{\textbf{0}j}(D^\ell)_{ji}P^T_{i\textbf{1}} \\
        &= \frac1{2^n}\sum_{i\in\Z_2^n}P_{\textbf{0}i}\lambda_i^\ell P^T_{i\textbf{1}} \\
        &= \frac1{2^n}\sum_{i\in\Z_2^n}\lambda_i^\ell \chi_i(\textbf{0})\chi_i(\textbf{1}) \\
        &= \frac1{2^n}\sum_{i\in\Z_2^n}\lambda_i^\ell (-1)^{i\cdot\textbf{0}}(-1)^{i\cdot \textbf{1}} \\
        &= \frac1{2^n}\sum_{i\in\Z_2^n}\lambda_i^\ell (-1)^{i\cdot \textbf{1}}.
\end{align*}
Notice that since $\textbf{1}=1\cdots1$,  $i\cdot\textbf{1}$ is the number of 1-digits of $i$, which is given by $\omega(i)$. so we have
\begin{align*}
    (A(Q_n)^\ell)_{\textbf{0}\textbf{1}} 
        &= \frac1{2^n}\sum_{i\in\Z_2^n}\lambda_i^\ell (-1)^{\omega(i)}.
\end{align*}
Now since $\lambda_i=n-2\omega(i)$ and has multiplicity $\ds{n \choose \omega(i)}$, we can rewrite this sum as
\[(A(Q_n)^\ell)_{\textbf{0}\textbf{1}} = \frac1{2^n}\sum_{k=0}^n (-1)^k(n-2k)^\ell{n \choose k}.\]
This gives us the number of walks from $\textbf{0}$ to $\textbf{1}$ of length $\ell$. To find the probability of such a walk, we divide by the total number of walks of length $\ell$, giving us
\[\frac1{2^nn^\ell}\sum_{k=0}^n (-1)^k(n-2k)^\ell{n \choose k}.\]


\newpage
\ex{4}{
    Let $R_n$ be the graph with vertex set $\Z_2^n$ but now with two vertices adjacent if they differ in exactly two positions. What are the eigenvalues of $R_n$?
}

Let $\beta=\{\delta_v: v\in\Z_2^n\}$ and $\Gamma=\{e_{ij}: i\ne j\}$ where $e_{ij}$ is the vector with ones in the $i$ and $j$th positions and zeros in every other position. So
\begin{align*}
    [\Phi_\Gamma]_\beta
        &= \begin{bmatrix}
            | & & | \\
            [\Phi_\Gamma(\delta_{0\dots0})]_\beta & \cdots & [\Phi_\Gamma(\delta_{1\dots1})]_\beta \\
            | & & |
        \end{bmatrix}. \\
\end{align*}
Column $v$ of this matrix is
\begin{align*}
    [\Phi_\Gamma(\delta_v)]_\beta
        &= \sum_{u\in\Z_2^n}\Phi_\Gamma\delta_v(u)\delta_u \\
        &= \sum_{u\in\Z_2^n}\left(\sum_{e_{ij}\in\Gamma}\delta_v(u+e_{ij})\right)\delta_u.
\end{align*}
Notice that $\ds\sum_{e_{ij}\in\Gamma}\delta_v(u+e_{ij})=1$ when $u$ and $v$ differ in exactly two positions, and equals zero otherwise. In other words, the $u,v$ coordinate of $[|phi_\Gamma]_\beta$ is 1 if $u\sim v$ in $R_n$, and zero otherwise. Therefore,
\[A(R_n) = [\Phi_\Gamma]_\beta,\]
And the eigenvalues are given by
\[\lambda_v = \sum_{e_{ij}\in\Gamma}(-1)^{v\cdot e_{ij}}\]
for all $v\in\Z_2^n$. Now since $v\cdot e_{ij}=v\cdot(e_i+e_j)$ for all $i\ne j$ and equals 0 when $i=j$, then we can rewrite the expression for the eigenvalues as
\begin{align*}
    \lambda_v 
        &= \sum_{i=1}^n\sum_{j=1}^n(-1)^{v\cdot (e_i + e_j)} - n \\
        &= \sum_{i=1}^n(-1)^{v\cdot e_i}\sum_{j=1}^n(-1)^{v \cdot e_j} - n \\
        &= \sum_{i=1}^n(-1)^{v\cdot e_i}(n-2\omega(v)) - n \\
        &= (n-2\omega(v))^2 - n.
\end{align*}


\end{document}