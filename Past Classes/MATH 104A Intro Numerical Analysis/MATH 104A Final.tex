\documentclass[12pt]{article}

% Packages
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb}

\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstset{
    backgroundcolor=\color{backcolour},   
    keywordstyle=\color{magenta},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}


% Problem Box
\setlength{\fboxsep}{4pt}
\newsavebox{\mybox}
\newenvironment{problem}
    {\begin{lrbox}{\mybox}\begin{minipage}{0.98\textwidth}}
    {\end{minipage}\end{lrbox}\framebox[\textwidth]{\usebox{\mybox}}}

% Default Commands
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newcommand{\ds}{\displaystyle}
\newcommand{\isp}[1]{\quad\text{#1}\quad}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\phi}{\varphi}
\renewcommand{\emptyset}{\varnothing}

% Extra Commands
\newcommand{\<}{\left\langle}
\renewcommand{\>}{\right\rangle}
\newcommand{\conj}[1]{\overline{#1}}
\newcommand{\PP}{\mathcal{P}}
\newcommand{\expp}[1]{\exp\!\left( #1 \right)}

\begin{document}
 
\title{Final\\
    \large MATH 104A Intro to Numerical Analysis
}
\author{Harry Coleman}
\date{December 13, 2020}
\maketitle

\section{}
\begin{problem}
    In this problem, we want to approximate the definite integral
    \[
        \int_0^{\frac{\pi}{2}} \sin 2x \,dx
    \]
    using various quadrature rules.
\end{problem}

\subsection{}
\begin{problem}
    Using the \textbf{Trapezoidal Rule} to approximate the integral.
\end{problem}
\medskip

The trapezoidal approximation of this integral gives us
\[
    \int_0^{\frac{\pi}{2}} \sin 2x \,dx 
        \approx \frac12 \left( \sin \pi + \sin 0 \right) \left( \frac{\pi}{2} - 0 \right)
        = \frac{\pi}{4}(0 - 0) = 0.
\]

\newpage
\subsection{}
\begin{problem}
    Using the \textbf{Composite Trapezoidal Rule} and the grid $x_j = jh$ with $h = \frac{\pi}{24}$ and $j = 0, 1, \dots, 12$ to approximate the integral.
\end{problem}
\medskip

The composite trapezoidal approximation of the integral of a function $f$ on the interval $[a, b]$, using the equidistributed nodes $x_j = a + jh$ for $j = 0, \dots, n$ is given by
\[
    \int_a^b f(x) \,dx \approx \frac{h}{2} \left( f(a) + \sum_{j = 1}^{n - 1} f(a + jh) + f(b) \right).
\]
We approximate the integral of $f(x) = \sin 2x$ on the interval $[0, \pi/2]$, taking $h = \frac{\pi}{24}$ and $n = 12$. The following code evaluates the above formula for these parameters.
\begin{lstlisting}[language=Python]
import math

def CTR():
    h = math.pi/24
    n = 12
    F = [math.sin(2*j*h) for j in range(0, n+1)]
    
    print((F[0] + 2*sum(F[1:n]) + F[-1]) * h/2)

CTR()
\end{lstlisting}
Running this code (see Jupyter file) gives us the approximation
\[
    \int_0^{\frac{\pi}{2}} \sin 2x \,dx \approx 0.9942818882921578.
\]

\newpage
\subsection{}
\begin{problem}
    Using the \textbf{Composite Simpson's Rule} and the grid $x_j = jh$ with $h = \frac{\pi}{24}$ and $j = 0, 1, 2, \dots, 12$ to approximate the integral.
\end{problem}
\medskip

The composite Simpson's rule approximation of the integral of a function $f$ on the interval $[a, b]$, using the equidistributed nodes $x_j = a + jh$ for $j = 0, \dots, n$ is given by
\[
    \int_a^b f(x) \,dx
        \approx \frac{h}{3} \left(
            f(x_0) + f(x_n) + 2 \sum_{j = 2}^{n/2 - 1} f(x_{2j}) + 4 \sum_{j = 1}^{n/2} f(x_{2j - 1})
        \right).
\]
We approximate the integral of $f(x) = \sin 2x$ on the interval $[0, \pi/2]$, taking $h = \frac{\pi}{24}$ and $n = 12$. The following code evaluates the above formula for these parameters.
\begin{lstlisting}[language=Python]
def CSR():
    h = math.pi/24
    n = 12
    F = [math.sin(2*j*h) for j in range(0, n+1)]
    
    print((F[0] + F[-1] + 2*sum(F[2:n:2]) + 4*sum(F[1:n:2])) * h/3)

CSR()
\end{lstlisting}
Running this code (see Jupyter file) gives us the approximation
\[
    \int_0^{\frac{\pi}{2}} \sin 2x \,dx \approx 1.0000263121705928.
\]


\newpage
\subsection{}
\begin{problem}
    Let the uniform grid $x_j = jh$ with $h = \frac{\pi}{2n}$ and $j = 0, 1, \dots, n$ for a \textbf{positive integer} $n$. Using the formula for error term estimate of \textbf{Composite Trapezoidal Rule} to determine values of $n$ that ensure an approximation error less than $0.00002$. You are allowed to use a calculator to compute $n$.
\end{problem}
\medskip

The error of the composite trapezoidal rule on these parameters is given by
\[
    \frac{1}{12} \left( \frac{\pi}{2} - 0 \right) \left( \frac{\pi}{2n} \right)^2 \sin 2 \xi = \frac{\pi^3 \sin 2\xi}{96 n^2}, \quad \xi \in (0, \pi/2).
\]
Note that the maximum $\sin 2 \xi$ attains on $(0, \pi/2)$ is $1$, for $\xi = \pi/4$. Then the error is bounded by
\[
    \frac{\pi^3}{96 n^2}.
\]
Bounding this value for a given $\eps > 0$, we find
\begin{align*}
    \frac{\pi^3}{96 n^2} &< \eps, \\[1em]
    \frac{\pi^3}{96 \eps} &< n^2, \\[1em]
    \sqrt{\frac{\pi^3}{96 \eps}} &< n.
\end{align*}
Taking $\eps = 0.00002$ (see Jupyter file), we obtain a lower bound
\[
    n > \sqrt{\frac{\pi^3}{96 \cdot 0.00002}} \approx 127.07911881051172.
\]
Thus, for $n \geq 128$, we ensure an approximation error less than $0.00002$.


\newpage
\subsection{}
\begin{problem}
    Suppose a quadrature rule $Q_h(f)$ for $\int_a^b f(x) \,dx$ satisfies
    \[
        Q_h(f) = \int_a^b f(x) \,dx + c_1 h^4 + c_2 h^6 + \cdots + c_k h^{2k + 2} + \cdots.
    \]
    Find a formula that combines $Q_h(f)$ and $Q_{\frac{h}{2}}(f)$ to give $\int_a^b f(x) \,dx + O(h^6)$.
\end{problem}
\medskip

Let $I$ denote the integral
\[
    I = \int_a^b f(x) \,dx.
\]
Using the formulas for $Q_h(f)$ and $Q_{\frac{h}{2}}(f)$ we have the following:
\begin{align*}
    I &= Q_h(f) - c_1 h^4 - \sum_{k = 2}^\infty c_k h^{2k + 2} \\[1em]
    I &= Q_{\frac{h}{2}}(f) - c_1 \frac{h^4}{2^4}  - \sum_{k = 2}^\infty c_k\frac{h^{2k + 2}}{2^{2k + 2}}.
\end{align*}
We combine these to cancel the $h^4$ terms, obtaining
\begin{align*}
    I - 16I &= Q_h(f) - 16 Q_{\frac{h}{2}}(f) - \sum_{k = 2}^\infty c_k h^{2k + 2} + 16 \sum_{k = 2}^\infty c_k \frac{h^{2k + 2}}{2^{2k + 2}}, \\[1em]
    -15 I &= Q_h(f) - 16 Q_{\frac{h}{2}}(f) - \sum_{k = 2}^\infty c_k \left( 1 -  \frac1{2^{2k - 2}} \right) h^{2k + 2}.
\end{align*}
Thus, we obtain the combined quadrature rule
\[
    \frac{Q_h(f) - 16Q_{\frac{h}{2}}(f)}{15} = \int_a^b f(x) \,dx + d_2 h^6 + \cdots + d_k h^{2k + 2} + \cdots,
\]
where
\[
    d_k = \frac{c_k}{15} \left( 1 -  \frac1{2^{2k - 2}} \right).
\]

\newpage
\section{}
\begin{problem}
    Let $s_0 = 1 + (x + 1)^3$ for $-1 \leq x \leq 0$. Determine $s_1(x)$ for $0 \leq x \leq 1$ such that
    \[
        s(x) = \begin{cases}
            s_0(x) & \text{for $-1 \leq x \leq 0$} \\
            s_1(x) & \text{for $\phantom{-}0 \leq x \leq 1$}
        \end{cases}
    \]
    is a natural cubic spline on $[-1, 1]$ with nodes at $-1, 0, 1$.
\end{problem}
\medskip

Let the cubic polynomial $s_1(x)$ be given by
\[
    s_1(x) = ax^3 + bx^2 + cx + d.
\]
In order for $s(x)$ to be a natural cubic spline, the following must be satisfied
\begin{align*}
    s_1(0) &= s_0(0), \\
    s_1'(0) &= s_0'(0), \\
    s_1''(0) &= s_0''(0), \\
    s_1''(1) &= 0.
\end{align*}
We now find
\begin{align*}
    s_1(0) &= a(0)^3 + b(0)^2 + c(0) + d = d, \\
    s_0(0) &= 1 + (0 + 1)^3 = 2,
\end{align*}
and the first condition implies $d = 2$. Next,
\begin{align*}
    s_1'(0) &= 3a(0)^2 + 2b(0) + c = c, \\
    s_0'(0) &= 3(0 + 1)^2 = 3,
\end{align*}
and the second condition implies $c = 3$. Next,
\begin{align*}
    s_1''(0) &= 6a(0) + 2b = 2b, \\
    s_0''(0) &= 6(0 + 1) = 6,
\end{align*}
and the third condition implies $b = 3$. Finally,
\[
    s_1''(1) = 6a(1) + 2b = 6a + 6,
\]
and the fourth condition implies $a = -1$. Thus, we have
\[
    s_1(x) = -x^3 + 3x^2 + 3x + 2.
\]


\section{}
\begin{problem}
    Given two discrete, periodic functions $\{f_m\}_{m=0}^{N-1}$ and $\{g_m\}_{m=0}^{N-1}$, we define their convolution, $f * g$, as the discrete function given by
    \[
        (f * g)_m = \sum_{s=0}^{N-1} f_{m-s} g_s, \quad m = 0, 1, \dots, N-1.
    \]
    We define the Discrete Fourier Transform of $\{f_m\}_{m=0}^{N-1}$ by
    \[
        \widehat{f}_k = \sum_{m=0}^{N-1} f_m e^{- \frac{2 \pi i mk}{N}}, \quad k = 0, 1, \dots, N-1.
    \]
\end{problem}

\subsection{}
\begin{problem}
    Show that
    \[
        f_m = \frac1N \sum_{k=0}^{N-1} \widehat{f_k} e^{\frac{2 \pi i mk}{N}}, \quad m = 0, 1, \dots, N-1.
    \]
\end{problem}

\begin{proof}
    We fix some $n \in \{0, \dots, N-1\}$. For a each $k \in \{0, \dots, N-1\}$, we have the discrete Fourier transform given by
    \[
        \widehat{f}_k = \sum_{m=0}^{N-1} f_m \expp{-i2\pi m \tfrac{k}{N}},
    \]
    where $\exp z = e^z$ is the complex exponential function. Solving for $f_n$ in each of these, we obtain the system of $N$ equations
    \[
        f_n = \widehat{f}_k\expp{i2\pi n \tfrac{k}{N}}
            - \sum_{\substack{m=0, \\ m \ne n}}^{N-1} f_m \expp{i2\pi (n-m) \tfrac{k}{N}},
            \quad k = 0, 1, \dots, N-1.
    \]
    Combining these, we obtain
    \[
        Nf_n = \sum_{k=0}^{N-1}\widehat{f}_k \expp{i2\pi n \tfrac{k}{N}}
            - \sum_{k=0}^{N-1}\sum_{\substack{m=0, \\ m \ne n}}^{N-1} f_m \expp{i2\pi (n-m) \tfrac{k}{N}}.
        \tag{1}
    \]
    Now, inspecting the summation on the right, we have
    \[
        \sum_{k=0}^{N-1}\sum_{\substack{m=0, \\ m \ne n}}^{N-1} f_m \expp{i2\pi (n-m) \tfrac{k}{N}}
            = \sum_{\substack{m=0, \\ m \ne n}}^{N-1} f_m \sum_{k=0}^{N-1} \expp{i2\pi (n-m) \tfrac{k}{N}}.
    \]
    Now since $e^{zk} = \left(e^z\right)^k$ for $k \in \Z$, then we have the partial sum of a geometric series
    \[
        \sum_{k=0}^{N-1} \expp{i2\pi (n-m) \tfrac{k}{N}}
            = \sum_{k=0}^{N-1} \expp{i2\pi (n-m) \tfrac{1}{N}}^k,
    \]
    whose sum is given by
    \[
        \frac{1 - \expp{i2\pi (n-m) \tfrac{1}{N}}^N}{1 - \expp{i2\pi (n-m) \tfrac{1}{N}}}
            = \frac{1 - \expp{i2\pi (n-m)}}{1 - \expp{i2\pi (n-m) \tfrac{1}{N}}}
            = \frac{1 - 1}{1 - \expp{i2\pi (n-m) \tfrac{1}{N}}}
            = 0.
    \]
    Note that the second equality above follows from the fact that $n-m$ is an integer, and the exponential of any integer multiple of $i2\pi$ is $1$. Substituting back into (1) and dividing by $N$ we obtain the desired equation
    \[
        f_n = \frac1N \sum_{k=0}^{N-1}\widehat{f}_k \expp{i2\pi n \tfrac{k}{N}}.
    \]

\end{proof}

\subsection{}
\begin{problem}
    Show that
    \[
        \widehat{(f * g)}_k = \widehat{f}_k \widehat{g}_k.
    \]
\end{problem}

\begin{proof}
    Applying first the definition of the discrete Fourier transform, then the result of 3.1, we obtain
    \[
        \widehat{(f * g)}_k
            = \sum_{m=0}^{N-1} (f * g)_m \expp{-i2\pi m \tfrac{k}{N}}
            = \sum_{m=0}^{N-1} \sum_{s=0}^{N-1} f_{m-s} g_s \expp{-i2\pi m \tfrac{k}{N}}.
    \]
    We rearrange the summation and apply the definition of the discrete Fourier transform,
    \begin{align*}
        \widehat{(f * g)}_k
            &= \sum_{s=0}^{N-1} g_s \sum_{m=0}^{N-1} f_{m-s} \expp{-i2\pi m \tfrac{k}{N}} \\[1em]
            &= \sum_{s=0}^{N-1} g_s \expp{-i2\pi s \tfrac{k}{N}} 
                \sum_{m=0}^{N-1} f_{m-s} \expp{-i2\pi (m - s) \tfrac{k}{N}} \\[1em]
            &= \sum_{s=0}^{N-1} g_s \expp{-i2\pi s \tfrac{k}{N}} \widehat{f}_k \\[1em]
            &= \widehat{f}_k \sum_{s=0}^{N-1} g_s \expp{-i2\pi s \tfrac{k}{N}} \\[1em]
            &= \widehat{f}_k \widehat{g}_k.
    \end{align*}
    
\end{proof}

\section{}
\begin{problem}
    The \textbf{normalized} Chebyshev polynomials on $x \in [-1, 1]$ are defined as $T_n(x) = \sqrt{2/\pi} \cos(n \cos^{-1} x)$, for $n \geq 1$ and $T_0(x) = \sqrt{1/\pi}$. Consider the expansion
    \[
        S_n(x) = \sum_{k=0}^n a_k T_k(x),
    \]
    where $\{T_0, T_1, \dots, T_n\}$ is a finite set of Chebyshev polynomials on $[-1, 1]$.
\end{problem}

\subsection{}
\begin{problem}
    Show the \textbf{normalized} Chebyshev polynomials are orthonormal with $\< T_m, T_n\>_\omega = \delta_{m,n}$ under the inner-product
    \[
        \<u, v\>_\omega = \int_{-1}^1 u(x) v(x) \omega(x) \,dx,
    \]
    where $\omega(x) = \frac{1}{\sqrt{1- x^2}}$.
\end{problem}

\begin{proof}
    For any pair $m, n$, we have
    \[
        \< T_m, T_n\>_\omega = \int_{-1}^1 T_m(x) T_n(x) \frac{dx}{\sqrt{1- x^2}}.
    \]
    On this interval, $\cos^{-1} x$ is a well-defined inverse of $\cos x$. Taking $\theta = \cos^{-1} x$, we rewrite the integration as
    \[
        \< T_m, T_n\>_\omega
            = \int_{\cos \pi}^{\cos{0}} T_m(\cos \cos^{-1} x) T_n(\cos \cos^{-1} x) \frac{dx}{\sqrt{1- x^2}}
            = \int_0^\pi T_m(\cos \theta) T_n(\cos \theta) \,d\theta.
    \]
    In particular, we have
    \[
        \< T_0, T_0\>_\omega
            = \int_0^\pi \frac{1}{\pi} \,d\theta
            = 1.
    \]
    And for any $m > 0$, we find
    \[
        \< T_m, T_0\>_\omega
            = \frac{\sqrt{2}}{\pi} \int_0^\pi \cos(m \theta) \,d\theta
            = \frac{\sqrt{2}}{\pi} \left( \frac{\sin(m\pi)}{m} - \frac{\sin(m0)}{m} \right)
            = 0.
    \]
    Now, suppose $m, n \geq 1$, then
    \begin{align*}
        \< T_m, T_n\>_\omega
            &= \frac{2}{\pi}\int_0^\pi \cos(m\theta) \cos(n\theta) \,d\theta \\
            &= \frac{1}{\pi} \left( \int_0^\pi \cos((m+n)\theta) \,d\theta + \int_0^\pi \cos((m-n)\theta) \,d\theta \right).
    \end{align*}
    Regardless of whether $m$ and $n$ are equal, we have
    \[
        \int_0^\pi \cos((m+n)\theta) \,d\theta = \frac{\sin((m+n)\pi)}{m+n} - \frac{\sin((m+n)0)}{m+n} = 0.
    \]
    Then if $m = n$, then
    \begin{align*}
        \< T_m, T_n\>_\omega
            = \frac{1}{\pi} \int_0^\pi \cos((m-n)\theta) \,d\theta 
            = \frac{1}{\pi} \int_0^\pi \cos0 \,d\theta
            = 1.
    \end{align*}
    And if $m \ne n$, then
    \begin{align*}
        \< T_m, T_n\>_\omega
            = \frac{1}{\pi} \int_0^\pi \cos((m-n)\theta) \,d\theta 
            = \frac{1}{\pi} \left( \frac{\sin((m-n)\pi)}{m-n} - \frac{\sin((m-n)0)}{m-n} \right)
            = 0.
    \end{align*}
    Thus, for all $m, n \geq 0$, we have $\< T_m, T_n\>_\omega = \delta_{m,n}$.
    
\end{proof}


\subsection{}
\begin{problem}
    To approximate the function $f(x) \in C[-1, 1]$, find the coefficients $a_k$, $k = 0, \dots, n$ so that $S_n(x)$ minimizes the least square error
    \[
        E(a_0, \dots, a_n) = \int_{-1}^1 (f(x) - S_n(x))^2 \omega(x) \,dx,
    \]
    where $\omega(x) \frac{1}{\sqrt{1- x^2}}$. You are required to show the derivation process.
\end{problem}
\medskip

Note that the set of Chebyshev polynomial $\{T_0, \dots, T_n\}$ form a basis for the space $P_n$ of real polynomials with degree at most $n$. This is because the dimension of $P_n$ is $n+1$, and the set of $n+1$ Chebyshev polynomials are orthonormal (In particular, they form an orthonormal basis). We denote by $\|\cdot\|_\omega$ the norm induced by the weighted inner product,
\[
    \|u\|_\omega = \sqrt{\< u, u \>_\omega}.
\]
Then if $(a_0, \dots, a_n)$ are the coefficients of $S_n$ as a combination of Chebyshev polynomials, the least square error is given by
\[
    E(a_0, \dots, a_n) = \| f - S_n \|_\omega^2.
\]

\begin{proposition}
    If $\< f - S_n, p\>_\omega = 0$ for all $p \in P_n$, then $S_n$ minimizes $\| f - S_n \|_\omega^2$ in $P_n$.
\end{proposition}

\begin{proof}
    Suppose $S_n \in P_n$ such that $f - S_n$ is orthogonal to $P_n$. Let $p \in P_n$, then we have
    \[
        \|f - p\|_\omega^2 = \| f - S_n + S_n - p \|_\omega^2.
    \]
    Because $f - S_n$ is orthogonal to $P_n$, in particular it is orthogonal to $S_n - p \in P_n$. Then
    \[
        \|f - p\|_\omega^2 = \| f - S_n \|_\omega^2 + \| S_n - p \|_\omega^2 \geq \| f - S_n \|_\omega^2.
    \]
    Thus, $S_n$ minimizes the error in $P_n$.
    
\end{proof}

Because the set of Chebyshev polynomials forms a basis for $P_n$, then it is sufficient to find $S_n$ such that $f - S_n$ is orthogonal to each Chebyshev polynomial. That is, for each $k \in \{0, \dots, n\}$, we want
\[
    0 = \< f - S_n, T_k\>_\omega = \< f, T_k\>_\omega - \< S_n, T_k\>_\omega.
\]
Expanding the rightmost product, we find
\[
    \< S_n, T_k\>_\omega = \< a_0T_0 + \cdots + a_nT_n, T_k\>_\omega = \sum_{\ell=0}^n a_\ell \< T_\ell, T_k\> = \sum_{\ell=0}^n a_\ell \delta_{\ell, k} = a_k.
\]
Thus, the coefficients
\[
    a_k = \< f, T_k\>_\omega = \int_{-1}^1 f(x) T_k(x) \omega(x) \,dx, \quad k = 0, \dots, n,
\]
minimize the least square error $E(a_0, \dots, a_n)$.

This shows that, in general, given an inner product space of functions, the best approximation of that function in a particular subspace, with respect to the induced norm, will be the projection of that function onto the subspace. In this case, finding the projection of $f$ onto $P_n$ is helped by having the orthonormal basis for $P_n$ of Chebyshev polynomials.


\end{document}